# ğŸ” Elastic Auto Parser

**Auto-normalizaciÃ³n de logs a ECS** con Python + Logstash + Docker.
Detecta el tipo de log (Apache, Syslog, etc.), **mapea a Elastic Common Schema (ECS)** y lo envÃ­a a Elasticsearch para visualizar en Kibana.

## ğŸ§  Objetivo
Demostrar un pipeline reproducible de parsing y normalizaciÃ³n orientado a SIEM:
- **DetecciÃ³n automÃ¡tica** del tipo de fuente.
- **Mapeo a ECS** mediante reglas declarativas (YAML).
- **Entrega a Elasticsearch** vÃ­a Logstash.

## ğŸ§© Stack
- ElasticSearch + Kibana (Docker)
- Logstash (ingesta)
- Python 3.11 (detecciÃ³n y mapeo a ECS)
- NDJSON como formato intermedio

## ğŸš€ Quick start

```bash
# 1) Arrancar Elastic, Kibana y Logstash
docker compose up -d

# 2) Crear el entorno Python local (opcional si usarÃ¡s solo Docker)
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 3) Ejecutar el parser sobre data/raw y generar NDJSON ECS en data/out
python src/parser/main.py --in data/raw --out data/out/parsed.ndjson

# 4) Hacer que Logstash lea el NDJSON y lo envÃ­e a Elasticsearch
# (Logstash ya estÃ¡ leyendo data/out/parsed.ndjson por volumen compartido)
# Espera unos segundos y verifica el Ã­ndice en Kibana (http://localhost:5601)
```

## ğŸ“Š Ver en Kibana
- URL: `http://localhost:5601`
- Crea un Data View para `ecs-auto-*` y explora los campos ECS.

## ğŸ—ï¸ Estructura
- `src/parser`: detecciÃ³n por patrones â†’ mapeo ECS â†’ export NDJSON
- `config/parser/config.yaml`: reglas declarativas de mapeo
- `config/logstash/pipeline.conf`: input NDJSON â†’ output Elasticsearch

## ğŸ› ï¸ Makefile (atajos)
```bash
make up        # docker compose up -d
make down      # docker compose down -v
make parse     # corre el parser local
make reset     # borra datos del volumen
```

## ğŸ¤ Contribuir
PRs bienvenidos: nuevas detecciones, mappings ECS o fuentes de log.

## ğŸ“œ Licencia
MIT
